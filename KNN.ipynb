{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j3FvwcAFaavBk8fovII2PeJdsUHeT40v",
      "authorship_tag": "ABX9TyPzJiAjLu0d9sunuCrv/jmO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srinithya18/2048-Game/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wcl9F6KChjty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0049bb4-acbd-4a26-d63a-97b0c23191be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "47cf0d84"
      },
      "outputs": [],
      "source": [
        "dt=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/SPAM-210331-134237.csv\",encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=np.array(dt)\n",
        "# print(data.shape,data)\n",
        "# print(data[:5])\n",
        "data[:, [0, 1]] = data[:, [1, 0]]\n",
        "# print(data.shape,data[1])\n",
        "# print(data[:5])\n",
        "# z=np.zeros((116,1),dtype=np.float64)\n",
        "# print(z)\n",
        "# data= np.hstack((data, np.zeros((data.shape[0], 1), dtype=np.float64)))\n",
        "# np.append(data,z,axis=1)\n",
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QezVVIq0m1IH",
        "outputId": "179d9369-3447-46fa-fb2b-4225379cd729"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
            " 'ham']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    print(\"Preprocessing data...\")\n",
        "    \n",
        "    punc = string.punctuation           # Punctuation list\n",
        "    sw = stopwords.words('english')\n",
        "    for record in data:\n",
        "        # Remove common punctuation and symbols\n",
        "      for item in punc:\n",
        "        record[0] = record[0].replace(item, \"\")\n",
        "         # Lowercase all letters and remove stopwords \n",
        "      splittedWords = record[0].split()\n",
        "      newText = \"\"\n",
        "      for word in splittedWords:\n",
        "        if word not in sw:\n",
        "          word = word.lower()\n",
        "          newText = newText + \" \" + word\n",
        "        \n",
        "      record[0] = newText\n",
        "        \n",
        "    print(\"flag 2: preprocessed data\")        \n",
        "    return data\n",
        "data=preprocess_data(data)\n",
        "# print(data)"
      ],
      "metadata": {
        "id": "EVi7u5YttsUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040fa332-9255-4718-d627-a934c11c5767"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n",
            "flag 2: preprocessed data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# random.shuffle(data)\n",
        "# print(data[0])\n",
        "# train_data = data[0 : int(len(data)/2)]\n",
        "# test_data = data[int(len(data)/2) + 1 : -1]\n",
        "# # test_data = data[-101 : -1]\n",
        "# print(train_data[0])\n",
        "# print(test_data[0])"
      ],
      "metadata": {
        "id": "4e5g3JpVEnhg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "    print(\"Splitting data...\")\n",
        "    \n",
        "    features = data[:, 1]   # array containing all email text bodies\n",
        "    labels = data[:, 0]     # array containing corresponding labels\n",
        "    # print(labels)\n",
        "    training_labels, test_labels, training_data, test_data =\\\n",
        "        train_test_split(features, labels, test_size = 0.27, random_state = 42)\n",
        "    # print(training_data[0],'|', test_data[0],'|', training_labels[0],'|', test_labels[0])\n",
        "    # print(len(training_data),'|', len(test_data),'|',len(training_labels),'|', len(test_labels))\n",
        "    print(training_data[0],test_data[0])\n",
        "    print(\"flag 3: splitted data\")\n",
        "    return training_data, test_data, training_labels, test_labels\n",
        "# training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "# split_data(data)"
      ],
      "metadata": {
        "id": "WCo4KCOXva51"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSimilarity(record1, record2):\n",
        "  len1=len(record1[0].split())\n",
        "  len2=len(record2[0].split())\n",
        "  num_common=0\n",
        "  d={}\n",
        "  for word in record1[0].split():\n",
        "    if word not in d:\n",
        "      d[word]=1\n",
        "  for word in record2[0].split():\n",
        "    if word in d:\n",
        "      num_common+=1\n",
        "  similarity=num_common/(len1*len2)**0.5\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "NkQ3ZVlcptD4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findKNN(train_data,record,k,train_label):\n",
        "  for i in range(0,len(train_data)):\n",
        "    sim=getSimilarity(train_data[i],record)\n",
        "    train_data[i][-1]=sim\n",
        "  res=[]\n",
        "  for i in range(k):\n",
        "    max_sim=0\n",
        "    max_sim_index=0\n",
        "    \n",
        "    # testing_label=[]\n",
        "    for i in range(0,len(train_data)):\n",
        "      if train_data[i][-1]>max_sim:\n",
        "        max_sim=train_data[i][-1]\n",
        "        max_sim_index=i\n",
        "    train_data[max_sim_index][-1]=0\n",
        "    res.append(train_data[max_sim_index])\n",
        "    train_label.append(training_labels[max_sim_index])\n",
        "  return res"
      ],
      "metadata": {
        "id": "yuLN42cbsp3Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def judge(knn):\n",
        "  num_ham=0\n",
        "  num_spam=0\n",
        "  for r in range(len(knn)):\n",
        "    if(train_label[r]==\"ham\"):\n",
        "      num_ham+=1\n",
        "    else:\n",
        "      num_spam+=1\n",
        "  # print(num_ham)\n",
        "  # print(num_spam)\n",
        "  return \"ham\" if num_ham > num_spam else \"spam\"\n"
      ],
      "metadata": {
        "id": "pOGoT05HyTRM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(text):\n",
        "    wordCounts = dict()\n",
        "    for word in text.split():\n",
        "        if word in wordCounts:\n",
        "            wordCounts[word] += 1\n",
        "        else:\n",
        "            wordCounts[word] = 1\n",
        "    \n",
        "    return wordCounts"
      ],
      "metadata": {
        "id": "pKZHS2wH1GF8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
        "    total = 0\n",
        "    for word in test_WordCounts:\n",
        "      if word in test_WordCounts and word in training_WordCounts:\n",
        "        total += (test_WordCounts[word] - training_WordCounts[word])**2\n",
        "        del training_WordCounts[word]\n",
        "      else:\n",
        "        total += test_WordCounts[word]**2\n",
        "    for word in training_WordCounts:\n",
        "      total += training_WordCounts[word]**2\n",
        "    return total**0.5"
      ],
      "metadata": {
        "id": "Dd5p9zs02jBd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To get spam count and ham count of k nearest neighbours.we selected k values\n",
        "*italicized text*"
      ],
      "metadata": {
        "id": "hyOdnuZFHcwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(selected_Kvalues):\n",
        "    spam_count = 0\n",
        "    ham_count = 0\n",
        "    for value in selected_Kvalues:\n",
        "        if value[0] == \"spam\":\n",
        "            spam_count += 1\n",
        "        else:\n",
        "            ham_count += 1\n",
        "    if spam_count > ham_count:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return \"ham\"\n"
      ],
      "metadata": {
        "id": "uVNLE3mzGqMG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_classifier(training_data, training_labels, test_data, K, tsize):\n",
        "    print(\"Running KNN Classifier...\")\n",
        "    \n",
        "    result = []\n",
        "    counter = 1\n",
        "  # word counts for training email\n",
        "    training_WordCounts = [] \n",
        "    for training_text in training_data:\n",
        "            training_WordCounts.append(get_count(training_text))\n",
        "    for test_text in test_data:\n",
        "        similarity = [] # List of euclidean distances\n",
        "        test_WordCounts = get_count(test_text)  # word counts for test email\n",
        "        # Getting euclidean difference \n",
        "        for index in range(len(training_data)):\n",
        "            euclidean_diff =\\\n",
        "                euclidean_difference(test_WordCounts, training_WordCounts[index])\n",
        "            similarity.append([training_labels[index], euclidean_diff])\n",
        "        # Sort list in ascending order based on euclidean difference\n",
        "        similarity = sorted(similarity, key = lambda i:i[1])\n",
        "        selected_Kvalues = [] \n",
        "        for i in range(K):\n",
        "            selected_Kvalues.append(similarity[i])\n",
        "        # Predicting the class of email\n",
        "        result.append(get_class(selected_Kvalues))\n",
        "    return result"
      ],
      "metadata": {
        "id": "MEneHDedHa9q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy_score got using cosine distance.\n",
        "**bold text**"
      ],
      "metadata": {
        "id": "YeT-xsYCEr3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct=0\n",
        "wrong=0\n",
        "k=11\n",
        "training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "x=[0.0]*len(training_data)\n",
        "y=[0.0]*len(test_data)\n",
        "train_data= np.column_stack((training_data, x))\n",
        "testing_data= np.column_stack((test_data, y))\n",
        "for d in range(len(testing_data)):\n",
        "  train_label=[]\n",
        "  knn=findKNN(train_data,testing_data[d],k,train_label)\n",
        "  if judge(knn)==test_labels[d]:\n",
        "    correct+=1\n",
        "  else:\n",
        "    wrong+=1\n",
        "    # print(list(judge(knn)))\n",
        "    # print(d[1])\n",
        "accurate=correct/(correct+wrong)\n",
        "print(\"correct\",correct)\n",
        "print(\"wrong\",wrong)\n",
        "print(\"accuracy \",accurate*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKHCxbyezPMY",
        "outputId": "22ab698d-b6ad-4efd-8005-512f084ec717"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data...\n",
            " sorry ill call later  place man\n",
            "flag 3: splitted data\n",
            "correct 25\n",
            "wrong 7\n",
            "accuracy  78.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy_score using euclidean_distance"
      ],
      "metadata": {
        "id": "DCUF-KRIFJzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(K):\n",
        "    # data = load_data()\n",
        "    # data = preprocess_data(data)\n",
        "    training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "    tsize = len(test_data)\n",
        "    result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize)\n",
        "    # for i in range(tsize):\n",
        "      # print(test_labels[:tsize][i], result[i]) \n",
        "    accuracy = accuracy_score(test_labels[:tsize], result)\n",
        "    # print(test_labels[:tsize],np.array(result))\n",
        "    # precision = precision_score(test_labels[:tsize], result, pos_label=\"ham\")\n",
        "    # recall = recall_score(test_labels[:tsize], result, pos_label=\"ham\")\n",
        "    print(\"training data size\\t: \" + str(len(training_data)))\n",
        "    print(\"test data size\\t\\t: \" + str(len(test_data)))\n",
        "    print(\"K value\\t\\t\\t\\t: \" + str(K))\n",
        "    print(\"Samples tested\\t\\t: \" + str(tsize))\n",
        "    print(\"% accuracy\\t\\t\\t: \" + str(accuracy * 100))\n",
        "    # print(\"% precision\\t\\t\\t: \" + str(precision * 100))\n",
        "    # print(\"% recall\\t\\t\\t: \" + str(recall * 100))\n",
        "    print(\"Number correct\\t\\t: \" + str(int(accuracy * tsize)))\n",
        "    print(\"Number wrong\\t\\t: \" + str(int((1 - accuracy) * tsize)))\n",
        "main(30)"
      ],
      "metadata": {
        "id": "nsh73_Oyk_8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5232da25-e5cf-4a1c-bbd6-b7e15f4f6055"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data...\n",
            " sorry ill call later  place man\n",
            "flag 3: splitted data\n",
            "Running KNN Classifier...\n",
            "training data size\t: 84\n",
            "test data size\t\t: 32\n",
            "K value\t\t\t\t: 30\n",
            "Samples tested\t\t: 32\n",
            "% accuracy\t\t\t: 71.875\n",
            "Number correct\t\t: 23\n",
            "Number wrong\t\t: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6rhPHdFVIVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}