{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j3FvwcAFaavBk8fovII2PeJdsUHeT40v",
      "authorship_tag": "ABX9TyOmObtLBt+DVO4m10/EoDiP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Wcl9F6KChjty"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "47cf0d84"
      },
      "outputs": [],
      "source": [
        "dt=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/SPAM-210331-134237.csv\",encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=np.array(dt)\n",
        "# print(data.shape,data[0])\n",
        "print(data[:5])\n",
        "data[:, [0, 1]] = data[:, [1, 0]]\n",
        "# print(data.shape,data[1])\n",
        "print(data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QezVVIq0m1IH",
        "outputId": "6ae82339-3a1e-4b82-ca38-c7b94d67db2d"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['ham'\n",
            "  'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...']\n",
            " ['ham' 'Ok lar... Joking wif u oni...']\n",
            " ['spam'\n",
            "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"]\n",
            " ['ham' 'U dun say so early hor... U c already then say...']\n",
            " ['ham' \"Nah I don't think he goes to usf, he lives around here though\"]]\n",
            "[['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
            "  'ham']\n",
            " ['Ok lar... Joking wif u oni...' 'ham']\n",
            " [\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
            "  'spam']\n",
            " ['U dun say so early hor... U c already then say...' 'ham']\n",
            " [\"Nah I don't think he goes to usf, he lives around here though\" 'ham']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    print(\"Preprocessing data...\")\n",
        "    \n",
        "    punc = string.punctuation           # Punctuation list\n",
        "    sw = stopwords.words('english')\n",
        "    for record in data:\n",
        "        # Remove common punctuation and symbols\n",
        "      for item in punc:\n",
        "        record[0] = record[0].replace(item, \"\")\n",
        "         # Lowercase all letters and remove stopwords \n",
        "      splittedWords = record[0].split()\n",
        "      newText = \"\"\n",
        "      for word in splittedWords:\n",
        "        if word not in sw:\n",
        "          word = word.lower()\n",
        "          newText = newText + \" \" + word\n",
        "        \n",
        "      record[0] = newText\n",
        "        \n",
        "    print(\"flag 2: preprocessed data\")        \n",
        "    return data\n",
        "data=preprocess_data(data)\n",
        "# print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVi7u5YttsUz",
        "outputId": "a25722db-ad79-40c1-fd11-d7cc50231677"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n",
            "flag 2: preprocessed data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "    print(\"Splitting data...\")\n",
        "    \n",
        "    features = data[:, 1]   # array containing all email text bodies\n",
        "    labels = data[:, 0]     # array containing corresponding labels\n",
        "    # print(labels)\n",
        "    training_labels, test_labels, training_data, test_data =\\\n",
        "        train_test_split(features, labels, test_size = 0.27, random_state = 42)\n",
        "    print(training_data[0],'|', test_data[0],'|', training_labels[0],'|', test_labels[0])\n",
        "    print(len(training_data),'|', len(test_data),'|',len(training_labels),'|', len(test_labels))\n",
        "    print(\"flag 3: splitted data\")\n",
        "    return training_data, test_data, training_labels, test_labels"
      ],
      "metadata": {
        "id": "WCo4KCOXva51"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(text):\n",
        "    wordCounts = dict()\n",
        "    for word in text.split():\n",
        "        if word in wordCounts:\n",
        "            wordCounts[word] += 1\n",
        "        else:\n",
        "            wordCounts[word] = 1\n",
        "    \n",
        "    return wordCounts"
      ],
      "metadata": {
        "id": "pKZHS2wH1GF8"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
        "    total = 0\n",
        "    for word in test_WordCounts:\n",
        "      if word in test_WordCounts and word in training_WordCounts:\n",
        "        total += (test_WordCounts[word] - training_WordCounts[word])**2\n",
        "        del training_WordCounts[word]\n",
        "      else:\n",
        "        total += test_WordCounts[word]**2\n",
        "    for word in training_WordCounts:\n",
        "      total += training_WordCounts[word]**2\n",
        "    return total**0.5"
      ],
      "metadata": {
        "id": "Dd5p9zs02jBd"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To get spam count and ham count of k nearest neighbours.we selected k values\n",
        "*italicized text*"
      ],
      "metadata": {
        "id": "hyOdnuZFHcwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(selected_Kvalues):\n",
        "    spam_count = 0\n",
        "    ham_count = 0\n",
        "    for value in selected_Kvalues:\n",
        "        if value[0] == \"spam\":\n",
        "            spam_count += 1\n",
        "        else:\n",
        "            ham_count += 1\n",
        "    if spam_count > ham_count:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return \"ham\"\n"
      ],
      "metadata": {
        "id": "uVNLE3mzGqMG"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_classifier(training_data, training_labels, test_data, K, tsize):\n",
        "    print(\"Running KNN Classifier...\")\n",
        "    \n",
        "    result = []\n",
        "    counter = 1\n",
        "  # word counts for training email\n",
        "    training_WordCounts = [] \n",
        "    for training_text in training_data:\n",
        "            training_WordCounts.append(get_count(training_text))\n",
        "    for test_text in test_data:\n",
        "        similarity = [] # List of euclidean distances\n",
        "        test_WordCounts = get_count(test_text)  # word counts for test email\n",
        "        # Getting euclidean difference \n",
        "        for index in range(len(training_data)):\n",
        "            euclidean_diff =\\\n",
        "                euclidean_difference(test_WordCounts, training_WordCounts[index])\n",
        "            similarity.append([training_labels[index], euclidean_diff])\n",
        "        # Sort list in ascending order based on euclidean difference\n",
        "        similarity = sorted(similarity, key = lambda i:i[1])\n",
        "        selected_Kvalues = [] \n",
        "        for i in range(K):\n",
        "            selected_Kvalues.append(similarity[i])\n",
        "        # Predicting the class of email\n",
        "        result.append(get_class(selected_Kvalues))\n",
        "    return result"
      ],
      "metadata": {
        "id": "MEneHDedHa9q"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(K):\n",
        "    # data = load_data()\n",
        "    # data = preprocess_data(data)\n",
        "    training_data, test_data, training_labels, test_labels = split_data(data)\n",
        "    tsize = len(test_data)\n",
        "    result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize)\n",
        "    for i in range(tsize):\n",
        "      print(test_labels[:tsize][i], result[i]) \n",
        "    accuracy = accuracy_score(test_labels[:tsize], result)\n",
        "    print(\"training data size\\t: \" + str(len(training_data)))\n",
        "    print(\"test data size\\t\\t: \" + str(len(test_data)))\n",
        "    print(\"K value\\t\\t\\t\\t: \" + str(K))\n",
        "    print(\"Samples tested\\t\\t: \" + str(tsize))\n",
        "    print(\"% accuracy\\t\\t\\t: \" + str(accuracy * 100))\n",
        "    print(\"Number correct\\t\\t: \" + str(int(accuracy * tsize)))\n",
        "    print(\"Number wrong\\t\\t: \" + str(int((1 - accuracy) * tsize)))\n",
        "main(11)"
      ],
      "metadata": {
        "id": "nsh73_Oyk_8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091ae842-d2ea-42af-c397-971fc5ac8ed3"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data...\n",
            " sorry ill call later |  place man | ham | ham\n",
            "84 | 32 | 84 | 32\n",
            "flag 3: splitted data\n",
            "Running KNN Classifier...\n",
            "ham ham\n",
            "ham ham\n",
            "spam ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "spam ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "spam ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "spam ham\n",
            "ham ham\n",
            "spam ham\n",
            "spam ham\n",
            "spam ham\n",
            "spam ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "ham ham\n",
            "spam ham\n",
            "training data size\t: 84\n",
            "test data size\t\t: 32\n",
            "K value\t\t\t\t: 11\n",
            "Samples tested\t\t: 32\n",
            "% accuracy\t\t\t: 71.875\n",
            "Number correct\t\t: 23\n",
            "Number wrong\t\t: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6rhPHdFVIVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}